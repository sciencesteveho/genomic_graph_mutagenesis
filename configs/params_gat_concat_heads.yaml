# Params for GAT with concat_heads attention mode on Cerebras CS-2
train_input:
  data_processor: OGBGMOLCHEMBLDataProcessor
  dataset_dir: "/ocean/projects/bio210019p/stevesho/data/preprocess/tfrecords"
  num_targets: 4
  max_num_nodes: 5000
  # 9 atom features
  # element, chirality, degree, formal charge, number of hydrogens,
  # number of radicals, orbit hybridization, aromaticity, member of ring
  atom_feats: [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
  # 3 bond features (not used currently)
  # bond type, bond stereo, whether conjugated
  bond_feats: [5, 6, 2]
  batch_size: 32

predict_input:
  num_samples: 3770

model:
  model: GATModel
  hidden_dim: 512
  num_heads: 8
  gnn_depth: 10
  fc_depth: 2
  activation: relu
  attention_reduction: "concat_heads"
  layer_norm_epsilon: 1.0e-5
  ## cerebras parameters
  boundary_casting: False
  tf_summary: False
  mixed_precision: True

optimizer:
  optimizer_type: adam
  learning_rate: 3.0e-4
  epsilon: 1.0e-6
  loss_scaling_factor: "dynamic"

runconfig:
  # 25 epochs at batch 32 (total training examples 365047)
  max_steps: 285175
  save_checkpoints_steps: 11407   # every epoch at batch 32
  keep_checkpoint_max: 2